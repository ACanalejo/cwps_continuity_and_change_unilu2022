---
title: "Changing party-systems? Replication exercise on electoral volatility"
  
author: "Álvaro Canalejo-Molero"

date: "/ March 2022"

link-citations: yes

linkcolor: blue 

fontsize: 12pt

output:
  github_document:
    toc: false
  

---
------------------------------------------------
First, we have to **set up our project**. In the first chunk of code we define *knitr* parameters, install and load the necessary packages.

```{r setup, warning = FALSE, message = FALSE}
# Setting the compiling options
knitr::opts_chunk$set(echo = TRUE)

# Cleaning the environment
#rm(list = ls())

# Installing packages
#install.packages("kableExtra")
#install.packages("tidyverse")
#install.packages("readxl")

# Loading packages
library(knitr) # for compiling the document in pdf
library(kableExtra) # for LaTeX based tables
library(tidyverse) # load the tidyverse programming environment
library(readxl) # for importing xlsx files
```

Second, we must **get the data**. We will download it directly from the internet through R. We start by defining the URL where the data is hosted. 

The dataset **Party system volatility, regeneration and de-institutionalization in Western Europe (1945–2015)** (Emanuele, 2015) is on a dedicated webpage from the University Luiss Guido Carli. I have copied and pasted the URL already.

By default, any RMarkdown document sets the working directory on the same folder where you have downloaded the .Rmd file. We will get this path and add the name of the file that contains the data to it. Therefore, you must substitute the path in *dest* by the path of your working directory and leave the same file name at the end of the path.

Finally, we can proceed to download the data.

```{r, warning = FALSE, message = FALSE}
# Defining the data URL 
data_url <- "https://cise.luiss.it/cise/wp-content/uploads/downloads/2019/03/Dataset-of-Electoral-Volatility-and-its-internal-components-in-Western-Europe-1945-2015.xlsx"

# Get working directory path
getwd()

# Create the destine file in your working directory
## in my case
dest <- "C:/Users/acana/Dropbox/Research/GitHub/teaching/cwps_continuity_and_change_unilu2022/07_session/volatility_data.xlsx"

# Download the data to the working directory
download.file(data_url, dest, mode="wb")
```
The next step is **opening the data** contained in the .xlsx file.

```{r, warning = FALSE, message = FALSE}
# Open the data
vol_data <- read_excel("C:/Users/acana/Dropbox/Research/GitHub/teaching/cwps_continuity_and_change_unilu2022/07_session/volatility_data.xlsx")
```

Check at the environment tab below. Can you find the volatility_data object there? Great! That means that we have the data already!

Now the show must go on. **The first thing to do whenever we analyse a new dataset is taking a first look at its structure**. We will use the tidyverse environment instead of R base function for the most of it.

```{r, warning = FALSE, message = FALSE}
# Look at the data structure
glimpse(vol_data)
```

So what do we have here? The first thing we notice is that our dataset has **347 rows** (i.e, country-year observations) and **8 columns** (i.e., variables). Each of the rows above contains information on the **name** of the variable, the variable **type** and the **values** of the first number of observations.

Take your time to look at it.

You may notice that the last variable, **...8**, contains information on the dataset citation. We can look at it better with the commands *summary* and *head*.

```{r, warning = FALSE, message = FALSE}
# Get a summary of the variable "...8"
summary(vol_data$...8, n=10)

# Look at the first ten observations
head(vol_data$...8, n=10)
```

The command *summary* tell sus that it is a variable of type character (i.e., a string) with length 347, which means that has 347 characters (or letters) in total. The *head* command confirms that the first observation only contains the dataset citation and the rest is missing values, that in R are represented by *NA* (i.e., *not available*). We can remove it and take another look at the data.

```{r, warning = FALSE, message = FALSE}
# Remove the variable ...8
vol_data <- vol_data %>%
  select(-...8)

# Check the data structure again
glimpse(vol_data)
```
Ok! Now that we have kept only the necessary variables we should transform the variable *Country* into a factor. This allows us to group the information by each country category, which is definitely more useful than analysing single country-year elections.

```{r, warning = FALSE, message = FALSE}
# Converting character into factr variables
vol_data <- vol_data %>%
  mutate(Country = as.factor(Country))

# Check the data structure again
glimpse(vol_data)
```

Let's begin to explore the data!

We can start by some simple visualization. Remember the **preference distribution** from Session 5? We can use a **histogram** to visualize the distribution of any other numeric variable, such as total volatility. Looking at the data distribution is always useful and one of the first steps of any data analysis. The distribution tells us a few interesting things about the underlying phenomenon we are looking at.

```{r, warning = FALSE, message = FALSE}
# Histogram of Total Volatility
ggplot(vol_data, aes(x = TV)) +
  geom_histogram()
```

What does it tell us here? **Let's discuss it!**

Even though we learned a few things about volatility in Europe as a whole, the histogram doesn't tell us anything about cross-country differences. We may want to look at the **distribution within each country** now.

```{r, warning = FALSE, message = FALSE}
# Histogram of Total Volatility by country
ggplot(vol_data, aes(x = TV)) +
  geom_histogram() +
  facet_wrap(~Country)
```

Now we can see that there are **important differences** across countries. Some of them has very patterned volatility levels while others have wider distributions. In addition, some countries have more identifiable **outliers**, but we don't know the specific elections. Let's check these elections.

```{r, warning = FALSE, message = FALSE}
# Showing cases where total volatility > 30 only
vol_data %>% 
  filter(TV > 30)
```

**Does any of these elections sound familiar to you?**

Now let's do a little replication exercise! In their analyses, Chiaramonte and Emanuele (2017) divide the data in three periods: 1946-1968, 1969-1991 and 1992-2015. Then, they measure the average levels of Regeneration Volatility (*RegV*) for each country on each of the periods to see **what party systems have become more volatile over time** (our first research question) and if RegV has generally increased (our second research question). They display this information on a table. We will take a further step by summarising the same information but displaying it on a single plot.

First, we have to create a factor variable that represents each of the periods in a different category.

```{r, warning = FALSE, message = FALSE}
# Create period variable
vol_data <- vol_data %>% 
  mutate(Period = ifelse(Election_Year >= 1946 &
                         Election_Year <=1968, 1,
                        ifelse(Election_Year >= 1969 &
                               Election_Year <=1991, 2,
                           ifelse(Election_Year >= 1992 &
                                  Election_Year <=2015, 3, NA))),
  # transform period variable into a factor       
         Period = factor(Period,
                         levels = c("1",
                                    "2",
                                    "3"),
                         labels = c("1946-1968",
                                    "1969-1991",
                                    "1992-2015")))
# Get a summary of new the variable "period"
summary(vol_data$Period)
```

We can see that the first period has 99 elections, the second period 127 elections and the third period 121 elections. **But does regeneration volatility varies across them?**

We can start by visualizing the average levels of RegV and its dispersion by period using **boxplots**.

```{r, warning = FALSE, message = FALSE}
# Boxplot of Regeneration Volatility by period
ggplot(vol_data, aes(x = Period, y = RegV)) +
  geom_boxplot(aes(fill = Period))
```

The boxplots in this case are not too informative, because most elections have low RegV levels. What we can do is **using the logarithmic form of RegV**, which lowers the weight of outliers. As a trade-off, the interpretation of the values becomes less intuitive. However, this is not a problem if what we want to do is see temporal patterns.

```{r, warning = FALSE, message = FALSE}
# Boxplot of the log of Regeneration Volatility by period
ggplot(vol_data, aes(x = Period, y = log(RegV + 1))) +
  geom_boxplot(aes(fill = Period))
```

It seems that **volatility has indeed increased with time!** However, this tells us little about cross-country differences. **Let's look at the same plot by country.**

```{r, warning = FALSE, message = FALSE}
# Creating a Period variable with shorter labels for aes
vol_data <- vol_data %>%
  mutate(Period_lab = factor(Period,
                                labels = c("P1",
                                           "P2",
                                           "P3")))

# Boxplot of log RegV by period and country
ggplot(vol_data, aes(x = Period_lab, y = log(RegV + 1))) +
  geom_boxplot(aes(fill = Period)) +
  facet_wrap(~Country) +
  # Adding some aesthetic details
  xlab("Period") +
  ylab("log RegV") +
  guides(fill=guide_legend(title=""))
```

Great! This single plot summarises even more information than the table of Chiaramonte and Emanuele (2017) and in a more intutive way. As a final class activity, **let's discuss now what we can see here. They might have missed something!**

I hope you enjoyed our little walk through R :)

# References

Emanuele, V. (2015). Dataset of Electoral Volatility and its internal components in Western Europe (1945-2015). Rome: Italian Center for Electoral Studies.

Chiaramonte, A., & Emanuele, V. (2017). Party system volatility, regeneration and de-institutionalization in Western Europe (1945–2015). Party Politics, 23(4), 376–388.
